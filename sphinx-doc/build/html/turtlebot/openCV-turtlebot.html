

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>ROS OpenCV with Turtlebot &mdash; Gaitech EDU 2.5 documentation</title>
  

  
  
    <link rel="shortcut icon" href="../_static/gaitech32.jpg"/>
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="Gaitech EDU 2.5 documentation" href="../index.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> Gaitech EDU
          

          
            
            <img src="../_static/gaitechlogo150.png" class="logo" />
          
          </a>

          
            
            
              <div class="version">
                2.5
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_started/get-started.html">Get Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ros/ros-tutorials.html">ROS Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../roslink/index.html">ROSLink</a></li>
<li class="toctree-l1"><a class="reference internal" href="turtlebot-tutorials.html">Turtlebot Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../drones/index.html">Drones Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../gapter/index.html">Gapter Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../video/index.html">Video Streaming Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../dronemap/index.html">Dronemap Planner</a></li>
<li class="toctree-l1"><a class="reference internal" href="../contributors/index.html">Contributors</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">Gaitech EDU</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
      
    <li>ROS OpenCV with Turtlebot</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/turtlebot/openCV-turtlebot.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="ros-opencv-with-turtlebot">
<span id="opencv-turtlebot"></span><h1>ROS OpenCV with Turtlebot<a class="headerlink" href="#ros-opencv-with-turtlebot" title="Permalink to this headline">¶</a></h1>
<p>In this tutorial you will learn how to configure your turtlebot robot with OpenCV to stream videos from <code class="docutils literal"><span class="pre">Microsoft</span> <span class="pre">Kinect</span></code> or <code class="docutils literal"><span class="pre">Asus</span></code> cameras.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<ul class="last simple">
<li>Make sure that you completed installing all the required packages in the previous tutorials <a class="reference internal" href="openKinect-turtlebot.html#openkinect-turtlebot"><span class="std std-ref">Setting-up 3D Sensor for the Turtlebot</span></a> and <a class="reference internal" href="network-config-doc.html#network-config-doc"><span class="std std-ref">Network Configuration</span></a> and your network set-up is working fine between the ROS Master node and the host node.</li>
</ul>
</div>
<div class="section" id="installing-and-testing-camera-drivers">
<h2>Installing and Testing Camera Drivers<a class="headerlink" href="#installing-and-testing-camera-drivers" title="Permalink to this headline">¶</a></h2>
<p>In this section you will learn how to install all the camera drivers either it is <code class="docutils literal"><span class="pre">Asus</span></code> or <code class="docutils literal"><span class="pre">Kinect</span></code> camera. After that you will learn how to test the camera and make sure if it works.</p>
<div class="section" id="installing-the-camera-drivers">
<h3>Installing the Camera Drivers<a class="headerlink" href="#installing-the-camera-drivers" title="Permalink to this headline">¶</a></h3>
<p>All you need to do is to install the ROS <code class="docutils literal"><span class="pre">openni</span></code> and <code class="docutils literal"><span class="pre">freenect</span></code> drivers by running the following command:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>sudo apt-get install ros-indigo-openni-* ros-indigo-openni2-* <span class="se">\ </span>ros-indigo-freenect-*
rospack profile
</pre></div>
</div>
</div>
<div class="section" id="testing-your-camera">
<h3>Testing your Camera<a class="headerlink" href="#testing-your-camera" title="Permalink to this headline">¶</a></h3>
<p>To be able to see the video stream coming from your camera we need to use the <code class="docutils literal"><span class="pre">image_view</span></code> <a class="reference external" href="http://wiki.ros.org/image_view">package</a> .</p>
<p>For <code class="docutils literal"><span class="pre">Microsoft</span> <span class="pre">Kinect</span></code> camera run the following command:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>roslaunch freenect_launch freenect.launch
</pre></div>
</div>
<p>For <code class="docutils literal"><span class="pre">Asus</span></code> camera run the following command:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>roslaunch openni2_launch openni2.launch
</pre></div>
</div>
<p>If there is no problem with your installation you will see some thing like this:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>process<span class="o">[</span>camera/camera_nodelet_manager-1<span class="o">]</span>: started with pid <span class="o">[</span><span class="m">18070</span><span class="o">]</span>
<span class="o">[</span>INFO<span class="o">]</span> <span class="o">[</span><span class="m">1420555647</span>.969035762<span class="o">]</span>: Initializing nodelet with <span class="m">4</span> worker
threads.
process<span class="o">[</span>camera/driver-2<span class="o">]</span>: started with pid <span class="o">[</span><span class="m">18078</span><span class="o">]</span>
Warning: USB events thread - failed to <span class="nb">set</span> priority. This might cause
loss of data...
process<span class="o">[</span>camera/rectify_color-3<span class="o">]</span>: started with pid <span class="o">[</span><span class="m">18112</span><span class="o">]</span>
process<span class="o">[</span>camera/depth_rectify_depth-4<span class="o">]</span>: started with pid <span class="o">[</span><span class="m">18126</span><span class="o">]</span>
etc.
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">You will see a couple of warnings about USB event threads, you can ignore them.</p>
</div>
<p>The color video stream uses the following topic to publish on <code class="docutils literal"><span class="pre">/camera/rgb/image_raw</span></code> which uses the <code class="docutils literal"><span class="pre">image_view</span></code> package. Run the following command:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>rosrun image_view image_view image:<span class="o">=</span>/camera/rgb/image_raw
</pre></div>
</div>
<p>After a few seconds you will see the video stream from your camera on a small window.</p>
</div>
</div>
<div class="section" id="installing-opencv-packages">
<h2>Installing OpenCV packages<a class="headerlink" href="#installing-opencv-packages" title="Permalink to this headline">¶</a></h2>
<p>You need to download the OpenCV packages by running the following commands:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>sudo apt-get install ros-indigo-vision-opencv libopencv-dev python-opencv
rospack profile
</pre></div>
</div>
<p>After installation type this command to make sure that you have successfully installed the packages:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>$ python
&gt;&gt;&gt; from cv2 import cv
&gt;&gt;&gt; quit<span class="o">()</span>
</pre></div>
</div>
<p>You can type the following command to make sure that the OpenCV Python library is installed in its proper location:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>locate cv2.so <span class="p">|</span> grep python
</pre></div>
</div>
<p>You will get an output like this:</p>
<img alt="../_images/openCV-python.png" class="align-center" src="../_images/openCV-python.png" />
</div>
<div class="section" id="transform-image-from-ros-to-opencv">
<h2>Transform Image from ROS to OpenCV<a class="headerlink" href="#transform-image-from-ros-to-opencv" title="Permalink to this headline">¶</a></h2>
<p>In this section you will learn how to recieve and transform images from ROS and transform them to OpenCV.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Make sure that you downloaded the <code class="docutils literal"><span class="pre">gaitech_edu</span></code> package from our GitHub <a class="reference external" href="https://github.com/aniskoubaa/gaitech_edu">repository</a></p>
</div>
<p>You will find a launch file called <code class="docutils literal"><span class="pre">turtlebot_openCV</span></code> in the following path <code class="docutils literal"><span class="pre">gaitech_edu/src/turtlebot/openCV/launch/turtlebot_openCV.launch</span></code>.</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>&lt;launch&gt;
        &lt;node <span class="nv">pkg</span><span class="o">=</span><span class="s2">&quot;gaitech_edu&quot;</span> <span class="nv">name</span><span class="o">=</span><span class="s2">&quot;turtlebot_openCV&quot;</span> <span class="nv">type</span><span class="o">=</span><span class="s2">&quot;turtlebot_openCV.py&quot;</span> <span class="nv">output</span><span class="o">=</span><span class="s2">&quot;screen&quot;</span>&gt;
        &lt;remap <span class="nv">from</span><span class="o">=</span><span class="s2">&quot;input_rgb_image&quot;</span> <span class="nv">to</span><span class="o">=</span><span class="s2">&quot;/camera/rgb/image_raw&quot;</span> /&gt;
        &lt;remap <span class="nv">from</span><span class="o">=</span><span class="s2">&quot;input_depth_image&quot;</span> <span class="nv">to</span><span class="o">=</span><span class="s2">&quot;/camera/depth/image_rect&quot;</span> /&gt;
        &lt;/node&gt;
&lt;/launch&gt;
</pre></div>
</div>
<p>Run the file in a terminal:</p>
<div class="highlight-bash"><div class="highlight"><pre><span></span>roslaunch gaitech_edu turtlebot_openCV.launch
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Make sure that your camera driver is running.</p>
<p>For <code class="docutils literal"><span class="pre">Microsoft</span> <span class="pre">Kinect</span></code> camera:</p>
<blockquote>
<div><div class="highlight-bash"><div class="highlight"><pre><span></span>roslaunch freenect_launch freenect.launch
</pre></div>
</div>
</div></blockquote>
<p>For <code class="docutils literal"><span class="pre">Asus</span></code> camera:</p>
<div class="last highlight-bash"><div class="highlight"><pre><span></span>roslaunch openni2_launch openni2.launch
</pre></div>
</div>
</div>
<p>This file will run a python script called <code class="docutils literal"><span class="pre">turtlebot_openCV.py</span></code> and you can find the file in the following path <code class="docutils literal"><span class="pre">gaitech_edu/src/turtlebot/openCV/scripts/turtlebot_openCV.py</span></code>. The code is well documented but we will have a look at a couple of parts of it.</p>
<p>All the OpenCV scripts have to import the <code class="docutils literal"><span class="pre">cv2</span></code> and the older version of it <code class="docutils literal"><span class="pre">cv2.cv</span></code> as it has some functions needed. The <code class="docutils literal"><span class="pre">Image</span></code> and <code class="docutils literal"><span class="pre">CamerInfo</span></code> are used for ROS messages. To be able to convert from ROS to OpenCV you need to import the <code class="docutils literal"><span class="pre">CvBridge</span></code> and <code class="docutils literal"><span class="pre">CvBridgeError</span></code> from the <code class="docutils literal"><span class="pre">cv_bridge</span></code> package. As for the last import <code class="docutils literal"><span class="pre">numpy</span></code>, it is used because OpenCV use it to process the images.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">rospy</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">cv2.cv</span> <span class="kn">as</span> <span class="nn">cv</span>
<span class="kn">from</span> <span class="nn">sensor_msgs.msg</span> <span class="kn">import</span> <span class="n">Image</span><span class="p">,</span> <span class="n">CameraInfo</span>
<span class="kn">from</span> <span class="nn">cv_bridge</span> <span class="kn">import</span> <span class="n">CvBridge</span><span class="p">,</span> <span class="n">CvBridgeError</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
</pre></div>
</div>
<p>This part is to initialize the two windows to display the images on.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="c1"># Create the OpenCV display window for the RGB image</span>
<span class="bp">self</span><span class="o">.</span><span class="n">cv_window_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">node_name</span>
<span class="n">cv</span><span class="o">.</span><span class="n">NamedWindow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cv_window_name</span><span class="p">,</span> <span class="n">cv</span><span class="o">.</span><span class="n">CV_WINDOW_NORMAL</span><span class="p">)</span>
<span class="n">cv</span><span class="o">.</span><span class="n">MoveWindow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cv_window_name</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">75</span><span class="p">)</span>

<span class="c1"># And one for the depth image</span>
<span class="n">cv</span><span class="o">.</span><span class="n">NamedWindow</span><span class="p">(</span><span class="s2">&quot;Depth Image&quot;</span><span class="p">,</span> <span class="n">cv</span><span class="o">.</span><span class="n">CV_WINDOW_NORMAL</span><span class="p">)</span>
<span class="n">cv</span><span class="o">.</span><span class="n">MoveWindow</span><span class="p">(</span><span class="s2">&quot;Depth Image&quot;</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">350</span><span class="p">)</span>
</pre></div>
</div>
<p>As menthioned before that this program will display two windows, one for the Image and one for the Depth Image so each methods of them is for its Image processing, converting and displaying.</p>
<p>The code is well explained for the Image function and the Depth Image.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">image_callback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="c1"># Use cv_bridge() to convert the ROS image to OpenCV format</span>
    <span class="c1"># Convert the ROS image to OpenCV format using a cv_bridge helper function</span>
    <span class="n">frame</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">convert_image</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="c1"># Process the image to detect and track objects or features</span>
    <span class="n">processed_image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_image</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>

    <span class="c1"># If the result is a greyscale image, convert to 3-channel for display purposes &quot;&quot;&quot;</span>
    <span class="c1">#if processed_image.channels == 1:</span>
        <span class="c1">#cv.CvtColor(processed_image, self.processed_image, cv.CV_GRAY2BGR)</span>

    <span class="c1"># Display the image.</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">node_name</span><span class="p">,</span> <span class="n">processed_image</span><span class="p">)</span>

    <span class="c1"># Process any keyboard commands</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">keystroke</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">waitKey</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">keystroke</span> <span class="o">!=</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
        <span class="n">cc</span> <span class="o">=</span> <span class="nb">chr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">keystroke</span> <span class="o">&amp;</span> <span class="mi">255</span><span class="p">)</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">cc</span> <span class="o">==</span> <span class="s1">&#39;q&#39;</span><span class="p">:</span>
            <span class="c1"># The user has press the q key, so exit</span>
            <span class="n">rospy</span><span class="o">.</span><span class="n">signal_shutdown</span><span class="p">(</span><span class="s2">&quot;User hit q key to quit.&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">depth_callback</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ros_image</span><span class="p">):</span>
    <span class="c1"># Use cv_bridge() to convert the ROS image to OpenCV format</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="c1"># Convert the depth image using the default passthrough encoding</span>
        <span class="n">depth_image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bridge</span><span class="o">.</span><span class="n">imgmsg_to_cv2</span><span class="p">(</span><span class="n">ros_image</span><span class="p">,</span> <span class="s2">&quot;passthrough&quot;</span><span class="p">)</span>
    <span class="k">except</span> <span class="n">CvBridgeError</span><span class="p">,</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">print</span> <span class="n">e</span>

    <span class="c1"># Convert the depth image to a Numpy array since most cv2 functions require Numpy arrays.</span>
    <span class="n">depth_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">depth_image</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="c1"># Normalize the depth image to fall between 0 (black) and 1 (white)</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">depth_array</span><span class="p">,</span> <span class="n">depth_array</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">NORM_MINMAX</span><span class="p">)</span>

    <span class="c1"># Process the depth image</span>
    <span class="n">depth_display_image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">process_depth_image</span><span class="p">(</span><span class="n">depth_array</span><span class="p">)</span>

    <span class="c1"># Display the result</span>
    <span class="n">cv2</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="s2">&quot;Depth Image&quot;</span><span class="p">,</span> <span class="n">depth_display_image</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>For more details about <code class="docutils literal"><span class="pre">cv_bridge</span></code> and <code class="docutils literal"><span class="pre">OpenCV</span></code> on ROS, please refer to the following ROS documentation pages:</p>
<blockquote class="last">
<div><ul class="simple">
<li><a class="reference external" href="http://wiki.ros.org/cv_bridge">cv_bridge</a>: A package that is used to convert between ROS images and OpenCV images.</li>
<li><a class="reference external" href="https://github.com/opencv/opencv/wiki">openCV</a>: A package of programming functions for realtime computer vision.</li>
</ul>
</div></blockquote>
</div>
<p>After a short time you will see some thing like this:</p>
<img alt="../_images/openCV.png" class="align-center" src="../_images/openCV.png" />
<p>To understand the whole process of transformation you can open the <code class="docutils literal"><span class="pre">python</span></code> script in the following path <code class="docutils literal"><span class="pre">gaitech_edu/src/turtlebot/openCV/scripts/turtlebot_openCV.py</span></code> , the file is well documented so you will be able to understand everything written inside the code.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">This code is originally from the <code class="docutils literal"><span class="pre">cv_bridge_opencv.py</span></code> file in the <code class="docutils literal"><span class="pre">rbx1_vision</span></code> package but with some other modifications.</p>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Gaitech.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'2.5',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
  
 
<script type="text/javascript">
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-54522619-2', 'auto');
  ga('send', 'pageview');

</script>


</body>
</html>